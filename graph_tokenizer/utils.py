import pickle
import matplotlib.pyplot as plt
import numpy as np
from collections import defaultdict
import math

def load_all_datasets():
    print("Loading and balancing all datasets...")
    datasets_to_load = ['BBBP', 'Tox21', 'ClinTox', 'HIV', 'BACE']
    splits = ['train', 'valid', 'test']
    graphs_by_dataset = defaultdict(dict)  # æ¯ä¸ªæ•°æ®é›†å¯¹åº”ä¸€ä¸ªä¸‰åˆ†å›¾é›†

    # 1. åŠ è½½æ‰€æœ‰æ•°æ®é›†
    for dname in datasets_to_load:
        with open(f'./datasets/{dname}/graphs.pkl', 'rb') as f:
            g = pickle.load(f)
            for split in splits:
                graphs_by_dataset[dname][split] = g[split]

    # 2. å¯¹ train åšå¹³è¡¡ï¼ˆvalid å’Œ test é€šå¸¸ä¸éœ€è¦å¤åˆ¶ï¼‰
    max_train_len = max(len(graphs_by_dataset[d]['train']) for d in datasets_to_load)
    print(f"Max train length across datasets: {max_train_len}")

    # 3. åˆå¹¶æ‰€æœ‰å›¾ç»“æ„ï¼Œå¤åˆ¶ train ä»¥å¹³è¡¡æ•°æ®é‡
    graphs_all = {split: [] for split in splits}
    for dname in datasets_to_load:
        for split in splits:
            graphs = graphs_by_dataset[dname][split]
            if split == 'train':
                # repeat_factor = math.ceil(max_train_len / len(graphs)) if len(graphs) > 0 else 1
                # balanced_graphs = (graphs * repeat_factor)[:max_train_len]  # åˆ‡åˆ°æœ€é•¿é•¿åº¦
                # graphs_all[split].extend(balanced_graphs)
                graphs_all[split].extend(graphs)
            else:
                graphs_all[split].extend(graphs)  # valid/test ä¸é‡å¤
    return graphs_all


def load_data(dataset):
    if dataset == 'all':
        graphs_all = load_all_datasets()
        return graphs_all
    else:
        file_path = f'datasets/{dataset}/graphs.pkl'
        with open(file_path, 'rb') as f:
            graphs = pickle.load(f)
        return graphs


def summarize_and_plot_metrics(metric_list):
    """
    è¾“å…¥æ˜¯ä¸€ä¸ªç”± metric dict æ„æˆçš„åˆ—è¡¨ï¼š
    [{'accuracy': ..., 'precision': ..., 'recall': ..., 'f1': ...}, ...]

    è¾“å‡ºæ¯ä¸ªæŒ‡æ ‡çš„å‡å€¼ã€æ–¹å·®ã€æœ€å°å€¼ã€æœ€å¤§å€¼ï¼Œå¹¶è¿›è¡Œå¯è§†åŒ–ã€‚
    """
    metrics = ['accuracy', 'precision', 'recall', 'f1']
    stats = {m: {} for m in metrics}
    values = {m: [] for m in metrics}

    # æ”¶é›†æ¯ä¸ªæŒ‡æ ‡çš„å€¼
    for entry in metric_list:
        for m in metrics:
            values[m].append(entry[m])

    # è®¡ç®—ç»Ÿè®¡é‡
    for m in metrics:
        arr = np.array(values[m])
        stats[m]['mean'] = np.mean(arr)
        stats[m]['std'] = np.std(arr)
        stats[m]['min'] = np.min(arr)
        stats[m]['max'] = np.max(arr)

    # æ‰“å°
    print("\nğŸ“Š Metric Summary:")
    for m in metrics:
        print(f"{m.capitalize():<10} | Mean: {stats[m]['mean']:.4f} | Std: {stats[m]['std']:.4f} | "
              f"Min: {stats[m]['min']:.4f} | Max: {stats[m]['max']:.4f}")

    # å¯è§†åŒ–
    plt.figure(figsize=(10, 4))
    for i, m in enumerate(metrics):
        plt.subplot(1, 4, i + 1)
        plt.hist(values[m], bins=50, color='skyblue', edgecolor='black')
        plt.title(m.capitalize())
        plt.xlabel("Value")
        plt.ylabel("Count")
        plt.grid(True)

    plt.suptitle("Metric Distribution Across Graphs")
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

    return stats

