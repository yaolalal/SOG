{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51f44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import multiprocessing\n",
    "import copy\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch,transformers\n",
    "from reference.llm_loader import reload_model_and_tokenizer\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from reference.utils import get_tokenizer\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import statistics\n",
    "import random\n",
    "random.seed(42)  # 设置随机种子以确保结果可复现\n",
    "\n",
    "reload_path = \"./models/second-stage-llama3.2-3b/checkpoints/long_texts_match/checkpoint-1011\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c18bcd3",
   "metadata": {},
   "source": [
    "🌟 构造smiles_to_struct_code的映射"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab85dd",
   "metadata": {},
   "source": [
    "🌟 构造训练/验证/测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a7a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing training split for dataset:  BBBP task p_np\n",
      "原始: Total=1631, Pos=1341 , Neg=290\n",
      "复制负样本: 290 -> 1341\n",
      "Processing BBBP_p_np split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 2682/2682 [00:02<00:00, 1113.90 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBP_p_np(TRAIN): Total=2682, Pos=1341 (50.00%), Neg=1341 (50.00%)\n",
      "Balancing training split for dataset:  Tox21 task NR-AR\n",
      "原始: Total=6258, Pos=250 , Neg=6008\n",
      "复制正样本: 250 -> 1201\n",
      "Processing Tox21_NR-AR split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 7209/7209 [00:03<00:00, 2256.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AR(TRAIN): Total=7209, Pos=1201 (16.66%), Neg=6008 (83.34%)\n",
      "Balancing training split for dataset:  Tox21 task NR-AR-LBD\n",
      "原始: Total=6258, Pos=193 , Neg=6065\n",
      "复制正样本: 193 -> 1213\n",
      "Processing Tox21_NR-AR-LBD split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 7278/7278 [00:03<00:00, 2256.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AR-LBD(TRAIN): Total=7278, Pos=1213 (16.67%), Neg=6065 (83.33%)\n",
      "Balancing training split for dataset:  Tox21 task NR-AhR\n",
      "原始: Total=6258, Pos=589 , Neg=5669\n",
      "复制正样本: 589 -> 1133\n",
      "Processing Tox21_NR-AhR split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 6802/6802 [00:03<00:00, 2157.46 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AhR(TRAIN): Total=6802, Pos=1133 (16.66%), Neg=5669 (83.34%)\n",
      "Balancing training split for dataset:  Tox21 task NR-Aromatase\n",
      "原始: Total=6258, Pos=208 , Neg=6050\n",
      "复制正样本: 208 -> 1210\n",
      "Processing Tox21_NR-Aromatase split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 7260/7260 [00:03<00:00, 2354.34 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-Aromatase(TRAIN): Total=7260, Pos=1210 (16.67%), Neg=6050 (83.33%)\n",
      "Balancing training split for dataset:  Tox21 task NR-ER\n",
      "原始: Total=6258, Pos=646 , Neg=5612\n",
      "复制正样本: 646 -> 1122\n",
      "Processing Tox21_NR-ER split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 6734/6734 [00:03<00:00, 2212.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-ER(TRAIN): Total=6734, Pos=1122 (16.66%), Neg=5612 (83.34%)\n",
      "Balancing training split for dataset:  Tox21 task NR-ER-LBD\n",
      "原始: Total=6258, Pos=299 , Neg=5959\n",
      "复制正样本: 299 -> 1191\n",
      "Processing Tox21_NR-ER-LBD split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 7150/7150 [00:03<00:00, 2312.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-ER-LBD(TRAIN): Total=7150, Pos=1191 (16.66%), Neg=5959 (83.34%)\n",
      "Balancing training split for dataset:  Tox21 task NR-PPAR-gamma\n",
      "原始: Total=6258, Pos=132 , Neg=6126\n",
      "复制正样本: 132 -> 1225\n",
      "Processing Tox21_NR-PPAR-gamma split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 7351/7351 [00:03<00:00, 2326.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-PPAR-gamma(TRAIN): Total=7351, Pos=1225 (16.66%), Neg=6126 (83.34%)\n",
      "Balancing training split for dataset:  Tox21 task SR-ARE\n",
      "原始: Total=6258, Pos=718 , Neg=5540\n",
      "复制正样本: 718 -> 1108\n",
      "Processing Tox21_SR-ARE split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 6648/6648 [00:03<00:00, 2170.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-ARE(TRAIN): Total=6648, Pos=1108 (16.67%), Neg=5540 (83.33%)\n",
      "Balancing training split for dataset:  Tox21 task SR-ATAD5\n",
      "原始: Total=6258, Pos=196 , Neg=6062\n",
      "复制正样本: 196 -> 1212\n",
      "Processing Tox21_SR-ATAD5 split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 7274/7274 [00:03<00:00, 2022.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-ATAD5(TRAIN): Total=7274, Pos=1212 (16.66%), Neg=6062 (83.34%)\n",
      "Balancing training split for dataset:  Tox21 task SR-HSE\n",
      "原始: Total=6258, Pos=281 , Neg=5977\n",
      "复制正样本: 281 -> 1195\n",
      "Processing Tox21_SR-HSE split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 7172/7172 [00:03<00:00, 2329.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-HSE(TRAIN): Total=7172, Pos=1195 (16.66%), Neg=5977 (83.34%)\n",
      "Balancing training split for dataset:  Tox21 task SR-MMP\n",
      "原始: Total=6258, Pos=711 , Neg=5547\n",
      "复制正样本: 711 -> 1109\n",
      "Processing Tox21_SR-MMP split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 6656/6656 [00:03<00:00, 2183.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-MMP(TRAIN): Total=6656, Pos=1109 (16.66%), Neg=5547 (83.34%)\n",
      "Balancing training split for dataset:  Tox21 task SR-p53\n",
      "原始: Total=6258, Pos=276 , Neg=5982\n",
      "复制正样本: 276 -> 1196\n",
      "Processing Tox21_SR-p53 split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 7178/7178 [00:03<00:00, 2379.05 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-p53(TRAIN): Total=7178, Pos=1196 (16.66%), Neg=5982 (83.34%)\n",
      "Balancing training split for dataset:  ClinTox task FDA_APPROVED\n",
      "原始: Total=1184, Pos=1105 , Neg=79\n",
      "复制负样本: 79 -> 221\n",
      "Processing ClinTox_FDA_APPROVED split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 1326/1326 [00:01<00:00, 716.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinTox_FDA_APPROVED(TRAIN): Total=1326, Pos=1105 (83.33%), Neg=221 (16.67%)\n",
      "Balancing training split for dataset:  ClinTox task CT_TOX\n",
      "原始: Total=1184, Pos=95 , Neg=1089\n",
      "复制正样本: 95 -> 217\n",
      "Processing ClinTox_CT_TOX split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 1306/1306 [00:01<00:00, 660.82 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinTox_CT_TOX(TRAIN): Total=1306, Pos=217 (16.62%), Neg=1089 (83.38%)\n",
      "Balancing training split for dataset:  HIV task HIV_active\n",
      "原始: Total=32896, Pos=1232 , Neg=31664\n",
      "复制正样本: 1232 -> 6332\n",
      "Processing HIV_HIV_active split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 37996/37996 [00:09<00:00, 3981.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV_HIV_active(TRAIN): Total=37996, Pos=6332 (16.66%), Neg=31664 (83.34%)\n",
      "Processing BACE_Class split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 1210/1210 [00:01<00:00, 660.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACE_Class(TRAIN): Total=1210, Pos=515 (42.56%), Neg=695 (57.44%)\n",
      "Processing BBBP_p_np split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 204/204 [00:01<00:00, 127.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-AR split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 434.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-AR-LBD split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 427.28 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-AhR split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 445.59 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-Aromatase split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 439.32 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-ER split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 435.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-ER-LBD split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 441.05 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-PPAR-gamma split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 425.19 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-ARE split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 440.59 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-ATAD5 split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 449.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-HSE split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 441.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-MMP split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 446.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-p53 split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 782/782 [00:01<00:00, 398.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ClinTox_FDA_APPROVED split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 148/148 [00:01<00:00, 88.26 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ClinTox_CT_TOX split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 148/148 [00:01<00:00, 86.02 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HIV_HIV_active split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 4112/4112 [00:02<00:00, 1517.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BACE_Class split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 151/151 [00:01<00:00, 88.27 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BBBP_p_np split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 204/204 [00:01<00:00, 116.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-AR split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 431.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-AR-LBD split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 441.28 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-AhR split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:02<00:00, 339.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-Aromatase split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 412.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-ER split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 416.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-ER-LBD split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 410.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_NR-PPAR-gamma split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 439.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-ARE split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 438.78 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-ATAD5 split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 393.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-HSE split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:02<00:00, 379.78 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-MMP split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 422.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tox21_SR-p53 split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 783/783 [00:01<00:00, 434.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ClinTox_FDA_APPROVED split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 148/148 [00:01<00:00, 86.62 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ClinTox_CT_TOX split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 148/148 [00:01<00:00, 83.23 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HIV_HIV_active split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 4112/4112 [00:02<00:00, 1649.87 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BACE_Class split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=48): 100%|██████████| 152/152 [00:01<00:00, 94.11 examples/s] \n"
     ]
    }
   ],
   "source": [
    "map1 = {\n",
    "    \"p_np\": (\n",
    "        \"Does this molecule have blood-brain barrier permeability (BBB penetration)? True for BBB permeable and False for not BBB permeable.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map2 = {\n",
    "    \"NR-AR\": (\n",
    "        \"Does this molecule activate the androgen receptor (NR-AR)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-AR-LBD\": (\n",
    "        \"Does this molecule activate the ligand-binding domain of the androgen receptor (NR-AR-LBD)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-AhR\": (\n",
    "        \"Does this molecule activate the aryl hydrocarbon receptor (NR-AhR)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-Aromatase\": (\n",
    "        \"Does this molecule inhibit the aromatase enzyme (NR-Aromatase)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-ER\": (\n",
    "        \"Does this molecule activate the estrogen receptor (NR-ER)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-ER-LBD\": (\n",
    "        \"Does this molecule activate the ligand-binding domain of the estrogen receptor (NR-ER-LBD)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-PPAR-gamma\": (\n",
    "        \"Does this molecule activate the peroxisome proliferator-activated receptor gamma (NR-PPAR-gamma)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-ARE\": (\n",
    "        \"Does this molecule activate the antioxidant response element (SR-ARE)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-ATAD5\": (\n",
    "        \"Does this molecule activate ATAD5 signaling (SR-ATAD5)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-HSE\": (\n",
    "        \"Does this molecule activate the heat shock element (SR-HSE)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-MMP\": (\n",
    "        \"Does this molecule activate the mitochondrial membrane potential stress response (SR-MMP)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-p53\": (\n",
    "        \"Does this molecule activate the p53 stress response pathway (SR-p53)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map3 = {\n",
    "    \"FDA_APPROVED\": (\n",
    "        \"Has this molecule been approved by the FDA? True for FDA approved and false for non-approved.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"CT_TOX\": (\n",
    "        \"Is this molecule associated with clinical toxicity? True for clinically toxic and false for non-toxic.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map4 = {\n",
    "    \"HIV_active\": (\n",
    "        \"Does this molecule inhibit HIV replication? True for active molecules which can inhibit HIV and false for inactive ones.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map5 = {\n",
    "    \"Class\": (\n",
    "        \"Is the binding result of the molecular on beta-secretase 1 true or false?\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "# for dname,mapping in zip(['BBBP', 'Tox21', 'ClinTox', 'HIV', 'BACE'],[map1,map2,map3,map4,map5]):\n",
    "#     print(dname,len(mapping))\n",
    "\n",
    "# 将多个mapping合为一个\n",
    "all_mapping = {**map1, **map2, **map3, **map4, **map5}\n",
    "# print(len(all_mapping))\n",
    "\n",
    "save_path = \"./phase1/datasets/all/codes_map.pt\"\n",
    "codes_map = torch.load(save_path,weights_only=True)\n",
    "label_desc_map = all_mapping\n",
    "\n",
    "datasets_to_load = ['BBBP', 'Tox21', 'ClinTox', 'HIV', 'BACE']\n",
    "prompt_template = \"\"\"\n",
    "You are a chemistry expert. Classify the given molecule into the correct category based on its molecular structure (token) and smiles expression. Each structure token represents a unique graph pattern (e.g., a kind of similar molecular graphs).\n",
    "[Molecule] {text_attribute}\n",
    "[Structure Token] <struct>{code}</struct>\n",
    "[Task] {task_desc} Output the complete correct answer from the following two options:\n",
    "1. {category_1}\n",
    "2. {category_2}\n",
    "[Answer]\"\"\"\n",
    "\n",
    "tool,assistant_name = get_tokenizer(tokenizer_path=reload_path)\n",
    "def process(example):\n",
    "    # smiles example['text']\n",
    "    text_attribute = example['smiles']\n",
    "    task = example['task']\n",
    "    code_number = example['code']\n",
    "    code = f'<gstruct_{code_number}>'\n",
    "    task_details = label_desc_map[task]\n",
    "    example['instruction'] = prompt_template.format(\n",
    "        text_attribute = text_attribute,\n",
    "        code = code,\n",
    "        task_desc = task_details[0],\n",
    "        category_1 = task_details[1],        \n",
    "        category_2 = task_details[2]\n",
    "    )\n",
    "    example['response'] = [task_details[1] if example['label'] == 1 else task_details[2]][0]\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": example['instruction']},\n",
    "        {\"role\": assistant_name, \"content\": example['response']},\n",
    "    ]\n",
    "    example[\"text\"] = tool.apply_chat_template(messages, tokenize=False)+\"<|end_of_text|>\"\n",
    "   \n",
    "    return example\n",
    "\n",
    "def seal_datasets(split='train'):\n",
    "    datasets = {}\n",
    "    start = 0\n",
    "    for dataset_name in datasets_to_load:\n",
    "        dataset_path = f\"./phase1/datasets/{dataset_name}/graph_attributes.pkl\"\n",
    "        with open(dataset_path, \"rb\") as f:\n",
    "            graphs = pickle.load(f)\n",
    "        tar_graphs = graphs[split]\n",
    "\n",
    "        tar_len = len(tar_graphs)\n",
    "        tar_codes = list(codes_map[split].values())[start: start + tar_len]\n",
    "        start += tar_len\n",
    "        assert len(tar_codes) == tar_len,'Length mismatch between tar_graphs and tar_codes'\n",
    "        for g,code in zip(tar_graphs,tar_codes):\n",
    "            g['code'] = code\n",
    "        \n",
    "        tasks = g['label'].keys()\n",
    "        for task in tasks:\n",
    "            # print('Processing '+task+' for dataset: ',dataset_name)\n",
    "            new_graphs = copy.deepcopy(tar_graphs)\n",
    "            for g in new_graphs:\n",
    "                g['label'] = g['label'][task]\n",
    "                g['task'] = task\n",
    "\n",
    "            if split == 'train' and dataset_name != 'BACE':\n",
    "                print('Balancing training split for dataset: ',dataset_name, 'task', task)\n",
    "                pos_samples = [g for g in new_graphs if g['label'] == 1]\n",
    "                neg_samples = [g for g in new_graphs if g['label'] == 0]\n",
    "                num_pos, num_neg = len(pos_samples), len(neg_samples)\n",
    "                num_total = num_pos + num_neg\n",
    "                print(f\"原始: Total={num_total}, Pos={num_pos} , Neg={num_neg}\")\n",
    "\n",
    "                if num_pos < num_neg:\n",
    "                    # 复制正样本\n",
    "                    target_len = int(num_neg / 5)\n",
    "                    repeat_factor = target_len // num_pos\n",
    "                    remainder = target_len % num_pos\n",
    "                    pos_samples_extended = pos_samples * repeat_factor + random.sample(pos_samples, remainder)\n",
    "                    print(f\"复制正样本: {num_pos} -> {len(pos_samples_extended)}\")\n",
    "                    balanced_graphs = pos_samples_extended + neg_samples\n",
    "                    random.shuffle(balanced_graphs)\n",
    "                elif num_neg < num_pos:\n",
    "                    # 复制负样本\n",
    "                    target_len = int(num_pos / 5)\n",
    "                    repeat_factor = target_len // num_neg \n",
    "                    remainder = target_len % num_neg \n",
    "                    if dataset_name == 'BBBP':\n",
    "                        repeat_factor = num_pos // num_neg\n",
    "                        remainder = num_pos % num_neg  \n",
    "                    neg_samples_extended = neg_samples * repeat_factor + random.sample(neg_samples, remainder)\n",
    "                    print(f\"复制负样本: {num_neg} -> {len(neg_samples_extended)}\")\n",
    "                    balanced_graphs = pos_samples + neg_samples_extended\n",
    "                    random.shuffle(balanced_graphs)\n",
    "                else:\n",
    "                    balanced_graphs = new_graphs\n",
    "            else:\n",
    "                balanced_graphs = new_graphs\n",
    "\n",
    "            raw_dataset = Dataset.from_list(balanced_graphs)\n",
    "            raw_dataset = raw_dataset.add_column(\"smiles\", raw_dataset[\"text\"])\n",
    "            raw_dataset = raw_dataset.remove_columns(\"text\")\n",
    "\n",
    "            print(f\"Processing {dataset_name}_{task} split: {split}\")\n",
    "\n",
    "            datasets[dataset_name+'_'+task] = raw_dataset.map(\n",
    "                process,\n",
    "                num_proc= multiprocessing.cpu_count(),\n",
    "                load_from_cache_file=False,\n",
    "                remove_columns=raw_dataset.column_names,\n",
    "            )\n",
    "            # === 统计正负样本数量和比例 ===\n",
    "            if split == 'train':\n",
    "                labels = raw_dataset[\"label\"]\n",
    "                pos = sum(1 for l in labels if l == 1)\n",
    "                neg = sum(1 for l in labels if l == 0)\n",
    "                total = len(labels)\n",
    "                pos_ratio = pos / total if total > 0 else 0\n",
    "                neg_ratio = neg / total if total > 0 else 0\n",
    "                print(f\"{dataset_name}_{task}(TRAIN): Total={total}, Pos={pos} ({pos_ratio:.2%}), Neg={neg} ({neg_ratio:.2%})\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "splits = ['train','valid','test']\n",
    "\n",
    "\n",
    "ds_dict = {}\n",
    "for split in splits:\n",
    "    ds_dict[split] = seal_datasets(split)\n",
    "\n",
    "# 存储ds_dict\n",
    "with open(\"./corpus/ds_dict_balanced.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ds_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab4b1b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 1631/1631 [00:02<00:00, 580.43 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:02<00:00, 2265.03 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:02<00:00, 2224.12 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:01<00:00, 5100.24 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:01<00:00, 5387.31 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:01<00:00, 5414.65 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:01<00:00, 5428.28 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:01<00:00, 4725.94 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:01<00:00, 4941.34 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:02<00:00, 2504.56 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:02<00:00, 2476.35 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:01<00:00, 5214.93 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 6258/6258 [00:01<00:00, 5246.26 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 1184/1184 [00:01<00:00, 1053.90 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 1184/1184 [00:01<00:00, 1036.19 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 32896/32896 [00:02<00:00, 12373.03 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 1210/1210 [00:02<00:00, 523.35 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 204/204 [00:02<00:00, 74.74 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 672.62 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 674.80 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 674.70 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:02<00:00, 296.53 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 688.78 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 711.23 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 710.52 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 714.02 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 732.62 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 698.98 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 398.53 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 782/782 [00:02<00:00, 362.16 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 148/148 [00:01<00:00, 135.76 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 148/148 [00:01<00:00, 137.60 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 4112/4112 [00:01<00:00, 3574.72 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 151/151 [00:01<00:00, 139.77 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 204/204 [00:01<00:00, 177.96 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 746.10 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 408.76 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 409.38 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 705.12 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 716.40 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 728.41 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 738.74 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 744.51 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:02<00:00, 336.76 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:02<00:00, 338.68 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 739.64 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 687.08 examples/s] \n",
      "Map (num_proc=128): 100%|██████████| 148/148 [00:01<00:00, 134.90 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 148/148 [00:01<00:00, 131.04 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 4112/4112 [00:01<00:00, 3571.34 examples/s]\n",
      "Map (num_proc=128): 100%|██████████| 152/152 [00:02<00:00, 60.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "map1 = {\n",
    "    \"p_np\": (\n",
    "        \"Does this molecule have blood-brain barrier permeability (BBB penetration)? True for BBB permeable and False for not BBB permeable.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map2 = {\n",
    "    \"NR-AR\": (\n",
    "        \"Does this molecule activate the androgen receptor (NR-AR)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-AR-LBD\": (\n",
    "        \"Does this molecule activate the ligand-binding domain of the androgen receptor (NR-AR-LBD)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-AhR\": (\n",
    "        \"Does this molecule activate the aryl hydrocarbon receptor (NR-AhR)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-Aromatase\": (\n",
    "        \"Does this molecule inhibit the aromatase enzyme (NR-Aromatase)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-ER\": (\n",
    "        \"Does this molecule activate the estrogen receptor (NR-ER)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-ER-LBD\": (\n",
    "        \"Does this molecule activate the ligand-binding domain of the estrogen receptor (NR-ER-LBD)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-PPAR-gamma\": (\n",
    "        \"Does this molecule activate the peroxisome proliferator-activated receptor gamma (NR-PPAR-gamma)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-ARE\": (\n",
    "        \"Does this molecule activate the antioxidant response element (SR-ARE)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-ATAD5\": (\n",
    "        \"Does this molecule activate ATAD5 signaling (SR-ATAD5)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-HSE\": (\n",
    "        \"Does this molecule activate the heat shock element (SR-HSE)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-MMP\": (\n",
    "        \"Does this molecule activate the mitochondrial membrane potential stress response (SR-MMP)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-p53\": (\n",
    "        \"Does this molecule activate the p53 stress response pathway (SR-p53)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map3 = {\n",
    "    \"FDA_APPROVED\": (\n",
    "        \"Has this molecule been approved by the FDA? True for FDA approved and false for non-approved.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"CT_TOX\": (\n",
    "        \"Is this molecule associated with clinical toxicity? True for clinically toxic and false for non-toxic.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map4 = {\n",
    "    \"HIV_active\": (\n",
    "        \"Does this molecule inhibit HIV replication? True for active molecules which can inhibit HIV and false for inactive ones.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map5 = {\n",
    "    \"Class\": (\n",
    "        \"Is the binding result of the molecular on beta-secretase 1 true or false?\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "# for dname,mapping in zip(['BBBP', 'Tox21', 'ClinTox', 'HIV', 'BACE'],[map1,map2,map3,map4,map5]):\n",
    "#     print(dname,len(mapping))\n",
    "\n",
    "# 将多个mapping合为一个\n",
    "all_mapping = {**map1, **map2, **map3, **map4, **map5}\n",
    "# print(len(all_mapping))\n",
    "\n",
    "save_path = \"./phase1/datasets/all/codes_map.pt\"\n",
    "codes_map = torch.load(save_path,weights_only=True)\n",
    "label_desc_map = all_mapping\n",
    "\n",
    "datasets_to_load = ['BBBP', 'Tox21', 'ClinTox', 'HIV', 'BACE']\n",
    "prompt_template = \"\"\"\n",
    "You are a chemistry expert. Classify the given molecule into the correct category based on its molecular structure (token) and smiles expression. Each structure token represents a unique graph pattern (e.g., a kind of similar molecular graphs).\n",
    "[Molecule] {text_attribute}\n",
    "[Structure Token] <struct>{code}</struct>\n",
    "[Task] {task_desc} Output the complete correct answer from the following two options:\n",
    "1. {category_1}\n",
    "2. {category_2}\n",
    "[Answer]\"\"\"\n",
    "\n",
    "tool,assistant_name = get_tokenizer(tokenizer_path=reload_path)\n",
    "def process(example):\n",
    "    # smiles example['text']\n",
    "    text_attribute = example['smiles']\n",
    "    task = example['task']\n",
    "    code_number = example['code']\n",
    "    code = f'<gstruct_{code_number}>'\n",
    "    task_details = label_desc_map[task]\n",
    "    example['instruction'] = prompt_template.format(\n",
    "        text_attribute = text_attribute,\n",
    "        code = code,\n",
    "        task_desc = task_details[0],\n",
    "        category_1 = task_details[1],        \n",
    "        category_2 = task_details[2]\n",
    "    )\n",
    "    example['response'] = [task_details[1] if example['label'] == 1 else task_details[2]][0]\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": example['instruction']},\n",
    "        {\"role\": assistant_name, \"content\": example['response']},\n",
    "    ]\n",
    "    example[\"text\"] = tool.apply_chat_template(messages, tokenize=False)+\"<|end_of_text|>\"\n",
    "   \n",
    "    return example\n",
    "\n",
    "def seal_datasets(split='train'):\n",
    "    datasets = {}\n",
    "    start = 0\n",
    "    for dataset_name in datasets_to_load:\n",
    "        dataset_path = f\"./phase1/datasets/{dataset_name}/graph_attributes.pkl\"\n",
    "        with open(dataset_path, \"rb\") as f:\n",
    "            graphs = pickle.load(f)\n",
    "        tar_graphs = graphs[split]\n",
    "\n",
    "        tar_len = len(tar_graphs)\n",
    "        tar_codes = list(codes_map[split].values())[start: start + tar_len]\n",
    "        start += tar_len\n",
    "        assert len(tar_codes) == tar_len,'Length mismatch between tar_graphs and tar_codes'\n",
    "        for g,code in zip(tar_graphs,tar_codes):\n",
    "            g['code'] = code\n",
    "        \n",
    "        tasks = g['label'].keys()\n",
    "        for task in tasks:\n",
    "            # print('Processing '+task+' for dataset: ',dataset_name)\n",
    "            new_graphs = copy.deepcopy(tar_graphs)\n",
    "            for g in new_graphs:\n",
    "                g['label'] = g['label'][task]\n",
    "                g['task'] = task\n",
    "\n",
    "            balanced_graphs = new_graphs\n",
    "\n",
    "            raw_dataset = Dataset.from_list(balanced_graphs)\n",
    "            raw_dataset = raw_dataset.add_column(\"smiles\", raw_dataset[\"text\"])\n",
    "            raw_dataset = raw_dataset.remove_columns(\"text\")\n",
    "\n",
    "            datasets[dataset_name+'_'+task] = raw_dataset.map(\n",
    "                process,\n",
    "                num_proc= multiprocessing.cpu_count(),\n",
    "                load_from_cache_file=False,\n",
    "                remove_columns=raw_dataset.column_names,\n",
    "            )\n",
    "            # === 统计正负样本数量和比例 ===\n",
    "            # labels = raw_dataset[\"label\"]\n",
    "            # pos = sum(1 for l in labels if l == 1)\n",
    "            # neg = sum(1 for l in labels if l == 0)\n",
    "            # total = len(labels)\n",
    "            # pos_ratio = pos / total if total > 0 else 0\n",
    "            # neg_ratio = neg / total if total > 0 else 0\n",
    "            # logger.info(f\"{dataset_name}_{task}: Total={total}, Pos={pos} ({pos_ratio:.2%}), Neg={neg} ({neg_ratio:.2%})\")\n",
    "            # print(f\"{dataset_name}_{task}: Total={total}, Pos={pos} ({pos_ratio:.2%}), Neg={neg} ({neg_ratio:.2%})\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "splits = ['train','valid','test']\n",
    "\n",
    "\n",
    "ds_dict = {}\n",
    "for split in splits:\n",
    "    ds_dict[split] = seal_datasets(split)\n",
    "\n",
    "# 存储ds_dict\n",
    "with open(\"./corpus/ds_dict_ori.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ds_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6debe95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 1631/1631 [00:01<00:00, 1145.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBP_p_np: Total=1631, Pos=1341 (82.22%), Neg=290 (17.78%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 12016/12016 [00:02<00:00, 4882.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AR: Total=12016, Pos=6008 (50.00%), Neg=6008 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 12130/12130 [00:02<00:00, 4126.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AR-LBD: Total=12130, Pos=6065 (50.00%), Neg=6065 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 11338/11338 [00:01<00:00, 5674.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AhR: Total=11338, Pos=5669 (50.00%), Neg=5669 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 12100/12100 [00:02<00:00, 4865.07 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-Aromatase: Total=12100, Pos=6050 (50.00%), Neg=6050 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 11224/11224 [00:01<00:00, 6946.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-ER: Total=11224, Pos=5612 (50.00%), Neg=5612 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 11918/11918 [00:01<00:00, 6605.21 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-ER-LBD: Total=11918, Pos=5959 (50.00%), Neg=5959 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 12252/12252 [00:01<00:00, 7028.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-PPAR-gamma: Total=12252, Pos=6126 (50.00%), Neg=6126 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 11080/11080 [00:01<00:00, 5798.56 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-ARE: Total=11080, Pos=5540 (50.00%), Neg=5540 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 12124/12124 [00:01<00:00, 6919.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-ATAD5: Total=12124, Pos=6062 (50.00%), Neg=6062 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 11954/11954 [00:01<00:00, 6615.87 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-HSE: Total=11954, Pos=5977 (50.00%), Neg=5977 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 11094/11094 [00:01<00:00, 6274.20 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-MMP: Total=11094, Pos=5547 (50.00%), Neg=5547 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 11964/11964 [00:01<00:00, 6320.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-p53: Total=11964, Pos=5982 (50.00%), Neg=5982 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 1184/1184 [00:01<00:00, 813.71 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinTox_FDA_APPROVED: Total=1184, Pos=1105 (93.33%), Neg=79 (6.67%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 2178/2178 [00:01<00:00, 1515.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinTox_CT_TOX: Total=2178, Pos=1089 (50.00%), Neg=1089 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 63328/63328 [00:08<00:00, 7092.14 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV_HIV_active: Total=63328, Pos=31664 (50.00%), Neg=31664 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 1390/1390 [00:01<00:00, 1008.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACE_Class: Total=1390, Pos=695 (50.00%), Neg=695 (50.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 204/204 [00:01<00:00, 157.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBP_p_np: Total=204, Pos=112 (54.90%), Neg=92 (45.10%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 607.46 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AR: Total=782, Pos=31 (3.96%), Neg=751 (96.04%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 588.83 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AR-LBD: Total=782, Pos=25 (3.20%), Neg=757 (96.80%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 593.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AhR: Total=782, Pos=87 (11.13%), Neg=695 (88.87%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 554.95 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-Aromatase: Total=782, Pos=45 (5.75%), Neg=737 (94.25%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 531.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-ER: Total=782, Pos=75 (9.59%), Neg=707 (90.41%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 582.86 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-ER-LBD: Total=782, Pos=29 (3.71%), Neg=753 (96.29%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 489.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-PPAR-gamma: Total=782, Pos=32 (4.09%), Neg=750 (95.91%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 605.68 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-ARE: Total=782, Pos=106 (13.55%), Neg=676 (86.45%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 603.89 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-ATAD5: Total=782, Pos=35 (4.48%), Neg=747 (95.52%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 559.67 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-HSE: Total=782, Pos=44 (5.63%), Neg=738 (94.37%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 588.83 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-MMP: Total=782, Pos=111 (14.19%), Neg=671 (85.81%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 782/782 [00:01<00:00, 579.29 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-p53: Total=782, Pos=75 (9.59%), Neg=707 (90.41%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 148/148 [00:01<00:00, 101.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinTox_FDA_APPROVED: Total=148, Pos=142 (95.95%), Neg=6 (4.05%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 148/148 [00:01<00:00, 102.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinTox_CT_TOX: Total=148, Pos=7 (4.73%), Neg=141 (95.27%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 4112/4112 [00:02<00:00, 1793.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV_HIV_active: Total=4112, Pos=81 (1.97%), Neg=4031 (98.03%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 151/151 [00:01<00:00, 95.30 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACE_Class: Total=151, Pos=84 (55.63%), Neg=67 (44.37%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 204/204 [00:01<00:00, 128.67 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBP_p_np: Total=204, Pos=107 (52.45%), Neg=97 (47.55%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 507.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AR: Total=783, Pos=27 (3.45%), Neg=756 (96.55%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 530.28 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AR-LBD: Total=783, Pos=19 (2.43%), Neg=764 (97.57%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 498.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-AhR: Total=783, Pos=92 (11.75%), Neg=691 (88.25%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 503.50 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-Aromatase: Total=783, Pos=47 (6.00%), Neg=736 (94.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 499.75 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-ER: Total=783, Pos=70 (8.94%), Neg=713 (91.06%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 518.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-ER-LBD: Total=783, Pos=21 (2.68%), Neg=762 (97.32%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 581.24 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_NR-PPAR-gamma: Total=783, Pos=22 (2.81%), Neg=761 (97.19%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 559.86 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-ARE: Total=783, Pos=118 (15.07%), Neg=665 (84.93%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 521.21 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-ATAD5: Total=783, Pos=33 (4.21%), Neg=750 (95.79%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 543.27 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-HSE: Total=783, Pos=47 (6.00%), Neg=736 (94.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 441.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-MMP: Total=783, Pos=96 (12.26%), Neg=687 (87.74%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 783/783 [00:01<00:00, 623.24 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tox21_SR-p53: Total=783, Pos=72 (9.20%), Neg=711 (90.80%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 148/148 [00:01<00:00, 107.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinTox_FDA_APPROVED: Total=148, Pos=139 (93.92%), Neg=9 (6.08%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 148/148 [00:01<00:00, 97.62 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinTox_CT_TOX: Total=148, Pos=10 (6.76%), Neg=138 (93.24%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 4112/4112 [00:01<00:00, 2272.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV_HIV_active: Total=4112, Pos=130 (3.16%), Neg=3982 (96.84%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=128): 100%|██████████| 152/152 [00:01<00:00, 106.31 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACE_Class: Total=152, Pos=92 (60.53%), Neg=60 (39.47%)\n"
     ]
    }
   ],
   "source": [
    "map1 = {\n",
    "    \"p_np\": (\n",
    "        \"Does this molecule have blood-brain barrier permeability (BBB penetration)? True for BBB permeable and False for not BBB permeable.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map2 = {\n",
    "    \"NR-AR\": (\n",
    "        \"Does this molecule activate the androgen receptor (NR-AR)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-AR-LBD\": (\n",
    "        \"Does this molecule activate the ligand-binding domain of the androgen receptor (NR-AR-LBD)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-AhR\": (\n",
    "        \"Does this molecule activate the aryl hydrocarbon receptor (NR-AhR)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-Aromatase\": (\n",
    "        \"Does this molecule inhibit the aromatase enzyme (NR-Aromatase)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-ER\": (\n",
    "        \"Does this molecule activate the estrogen receptor (NR-ER)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-ER-LBD\": (\n",
    "        \"Does this molecule activate the ligand-binding domain of the estrogen receptor (NR-ER-LBD)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"NR-PPAR-gamma\": (\n",
    "        \"Does this molecule activate the peroxisome proliferator-activated receptor gamma (NR-PPAR-gamma)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-ARE\": (\n",
    "        \"Does this molecule activate the antioxidant response element (SR-ARE)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-ATAD5\": (\n",
    "        \"Does this molecule activate ATAD5 signaling (SR-ATAD5)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-HSE\": (\n",
    "        \"Does this molecule activate the heat shock element (SR-HSE)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-MMP\": (\n",
    "        \"Does this molecule activate the mitochondrial membrane potential stress response (SR-MMP)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"SR-p53\": (\n",
    "        \"Does this molecule activate the p53 stress response pathway (SR-p53)? True for active and False for inactive.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map3 = {\n",
    "    \"FDA_APPROVED\": (\n",
    "        \"Has this molecule been approved by the FDA? True for FDA approved and false for non-approved.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ),\n",
    "    \"CT_TOX\": (\n",
    "        \"Is this molecule associated with clinical toxicity? True for clinically toxic and false for non-toxic.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map4 = {\n",
    "    \"HIV_active\": (\n",
    "        \"Does this molecule inhibit HIV replication? True for active molecules which can inhibit HIV and false for inactive ones.\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "map5 = {\n",
    "    \"Class\": (\n",
    "        \"Is the binding result of the molecular on beta-secretase 1 true or false?\",\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    )\n",
    "}\n",
    "# for dname,mapping in zip(['BBBP', 'Tox21', 'ClinTox', 'HIV', 'BACE'],[map1,map2,map3,map4,map5]):\n",
    "#     print(dname,len(mapping))\n",
    "\n",
    "# 将多个mapping合为一个\n",
    "all_mapping = {**map1, **map2, **map3, **map4, **map5}\n",
    "# print(len(all_mapping))\n",
    "\n",
    "save_path = \"./phase1/datasets/all/codes_map.pt\"\n",
    "codes_map = torch.load(save_path,weights_only=True)\n",
    "label_desc_map = all_mapping\n",
    "\n",
    "datasets_to_load = ['BBBP', 'Tox21', 'ClinTox', 'HIV', 'BACE']\n",
    "prompt_template = \"\"\"\n",
    "You are a chemistry expert. Classify the given molecule into the correct category based on its molecular structure (token) and smiles expression. Each structure token represents a unique graph pattern (e.g., a kind of similar molecular graphs).\n",
    "[Molecule] {text_attribute}\n",
    "[Structure Token] <struct>{code}</struct>\n",
    "[Task] {task_desc} Output the complete correct answer from the following two options:\n",
    "1. {category_1}\n",
    "2. {category_2}\n",
    "[Answer]\"\"\"\n",
    "\n",
    "tool,assistant_name = get_tokenizer(tokenizer_path=reload_path)\n",
    "def process(example):\n",
    "    # smiles example['text']\n",
    "    text_attribute = example['smiles']\n",
    "    task = example['task']\n",
    "    code_number = example['code']\n",
    "    code = f'<gstruct_{code_number}>'\n",
    "    task_details = label_desc_map[task]\n",
    "    example['instruction'] = prompt_template.format(\n",
    "        text_attribute = text_attribute,\n",
    "        code = code,\n",
    "        task_desc = task_details[0],\n",
    "        category_1 = task_details[1],        \n",
    "        category_2 = task_details[2]\n",
    "    )\n",
    "    example['response'] = [task_details[1] if example['label'] == 1 else task_details[2]][0]\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": example['instruction']},\n",
    "        {\"role\": assistant_name, \"content\": example['response']},\n",
    "    ]\n",
    "    example[\"text\"] = tool.apply_chat_template(messages, tokenize=False)+\"<|end_of_text|>\"\n",
    "   \n",
    "    return example\n",
    "\n",
    "def seal_datasets(split='train'):\n",
    "    datasets = {}\n",
    "    start = 0\n",
    "    for dataset_name in datasets_to_load:\n",
    "        dataset_path = f\"./phase1/datasets/{dataset_name}/graph_attributes.pkl\"\n",
    "        with open(dataset_path, \"rb\") as f:\n",
    "            graphs = pickle.load(f)\n",
    "        tar_graphs = graphs[split]\n",
    "\n",
    "        tar_len = len(tar_graphs)\n",
    "        tar_codes = list(codes_map[split].values())[start: start + tar_len]\n",
    "        start += tar_len\n",
    "        assert len(tar_codes) == tar_len,'Length mismatch between tar_graphs and tar_codes'\n",
    "        for g,code in zip(tar_graphs,tar_codes):\n",
    "            g['code'] = code\n",
    "        \n",
    "        tasks = g['label'].keys()\n",
    "        for task in tasks:\n",
    "            # print('Processing '+task+' for dataset: ',dataset_name)\n",
    "            new_graphs = copy.deepcopy(tar_graphs)\n",
    "            for g in new_graphs:\n",
    "                g['label'] = g['label'][task]\n",
    "                g['task'] = task\n",
    "\n",
    "            if split == 'train':\n",
    "                pos_samples = [g for g in new_graphs if g['label'] == 1]\n",
    "                neg_samples = [g for g in new_graphs if g['label'] == 0]\n",
    "                num_pos, num_neg = len(pos_samples), len(neg_samples)\n",
    "\n",
    "                if num_pos < num_neg:\n",
    "                    # 复制正样本\n",
    "                    print(f\"复制正样本: {num_pos} -> {num_neg}\")\n",
    "                    repeat_factor = num_neg // num_pos\n",
    "                    remainder = num_neg % num_pos\n",
    "                    pos_samples_extended = pos_samples * repeat_factor + random.sample(pos_samples, remainder)\n",
    "                    balanced_graphs = pos_samples_extended + neg_samples\n",
    "                    random.shuffle(balanced_graphs)\n",
    "                elif num_neg < num_pos:\n",
    "                    # 复制负样本\n",
    "                    print(f\"复制负样本: {num_neg} -> {num_pos}\")\n",
    "                    repeat_factor = num_pos // num_neg\n",
    "                    remainder = num_pos % num_neg\n",
    "                    neg_samples_extended = neg_samples * repeat_factor + random.sample(neg_samples, remainder)\n",
    "                    balanced_graphs = pos_samples + neg_samples_extended\n",
    "                    random.shuffle(balanced_graphs)\n",
    "                else:\n",
    "                    balanced_graphs = new_graphs\n",
    "            else:\n",
    "                balanced_graphs = new_graphs\n",
    "\n",
    "            raw_dataset = Dataset.from_list(balanced_graphs)\n",
    "            raw_dataset = raw_dataset.add_column(\"smiles\", raw_dataset[\"text\"])\n",
    "            raw_dataset = raw_dataset.remove_columns(\"text\")\n",
    "\n",
    "            datasets[dataset_name+'_'+task] = raw_dataset.map(\n",
    "                process,\n",
    "                num_proc= multiprocessing.cpu_count(),\n",
    "                load_from_cache_file=False,\n",
    "                remove_columns=raw_dataset.column_names,\n",
    "            )\n",
    "            # === 统计正负样本数量和比例 ===\n",
    "            # labels = raw_dataset[\"label\"]\n",
    "            # pos = sum(1 for l in labels if l == 1)\n",
    "            # neg = sum(1 for l in labels if l == 0)\n",
    "            # total = len(labels)\n",
    "            # pos_ratio = pos / total if total > 0 else 0\n",
    "            # neg_ratio = neg / total if total > 0 else 0\n",
    "            # logger.info(f\"{dataset_name}_{task}: Total={total}, Pos={pos} ({pos_ratio:.2%}), Neg={neg} ({neg_ratio:.2%})\")\n",
    "            # print(f\"{dataset_name}_{task}: Total={total}, Pos={pos} ({pos_ratio:.2%}), Neg={neg} ({neg_ratio:.2%})\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "splits = ['train','valid','test']\n",
    "ds_dict = {}\n",
    "for split in splits:\n",
    "    ds_dict[split] = seal_datasets(split)\n",
    "\n",
    "# 存储ds_dict\n",
    "with open(\"./corpus/ds_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ds_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ed884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_dict_ori：原始数据比例\n",
    "# ds_dict_balanced: 1:5平衡后的数据比例\n",
    "# ds_dict: 1:1平衡后的数据比例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for train of BBBP: length -- 1631; start -- 0.\n",
      "for train of Tox21: length -- 6258; start -- 1631.\n",
      "for train of ClinTox: length -- 1184; start -- 7889.\n",
      "for train of HIV: length -- 32896; start -- 9073.\n",
      "for train of BACE: length -- 1210; start -- 41969.\n",
      "for valid of BBBP: length -- 204; start -- 0.\n",
      "for valid of Tox21: length -- 782; start -- 204.\n",
      "for valid of ClinTox: length -- 148; start -- 986.\n",
      "for valid of HIV: length -- 4112; start -- 1134.\n",
      "for valid of BACE: length -- 151; start -- 5246.\n",
      "for test of BBBP: length -- 204; start -- 0.\n",
      "for test of Tox21: length -- 783; start -- 204.\n",
      "for test of ClinTox: length -- 148; start -- 987.\n",
      "for test of HIV: length -- 4112; start -- 1135.\n",
      "for test of BACE: length -- 152; start -- 5247.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "save_path = \"./phase1/datasets/all/codes_map.pt\"\n",
    "codes_map = torch.load(save_path,weights_only=True)\n",
    "datasets_to_load = ['BBBP', 'HIV', 'BACE', 'ClinTox','Tox21']\n",
    "\n",
    "# 生成 SMILES -> code 的映射字典\n",
    "# Returns:\n",
    "#     dict: {smiles_string: code}\n",
    "\n",
    "smiles_to_code = defaultdict(dict)\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    tar_len = 0\n",
    "    start = 0\n",
    "    for dataset_name in datasets_to_load:\n",
    "        dataset_path = f\"./phase1/datasets/{dataset_name}/graph_attributes.pkl\"\n",
    "        with open(dataset_path, \"rb\") as f:\n",
    "            graphs = pickle.load(f)  # graphs 是一个 dict，里面按 split 存数据\n",
    "        \n",
    "        tar_graphs = graphs[split]\n",
    "        tar_len = len(tar_graphs)\n",
    "        print(f\"for {split} of {dataset_name}: length -- {tar_len}; start -- {start}.\")\n",
    "\n",
    "        tar_codes = list(codes_map[split].values())[start: start + tar_len]\n",
    "        start += tar_len\n",
    "\n",
    "        assert len(tar_codes) == tar_len, \\\n",
    "            f\"Length mismatch: graphs={tar_len}, codes={len(tar_codes)} for dataset {dataset_name}\"\n",
    "\n",
    "        for g, code in zip(tar_graphs, tar_codes):\n",
    "            # 假设 g 里有 'smiles' 字段，如果是别的字段名需要改\n",
    "            smiles_to_code[dataset_name][g['text']] = code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c2e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES->code 映射已保存到 ./corpus/smiles_to_code.pkl\n",
      "SMILES->code 映射已加载自 ./corpus/smiles_to_code.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = './corpus/smiles_to_code.pkl'\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(smiles_to_code, f)\n",
    "print(f\"SMILES->code 映射已保存到 {save_path}\")\n",
    "\n",
    "with open(save_path, \"rb\") as f:\n",
    "    smiles_to_code = pickle.load(f)\n",
    "print(f\"SMILES->code 映射已加载自 {save_path}\")\n",
    "len(smiles_to_code['BACE'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a50f54",
   "metadata": {},
   "source": [
    "🌟 构造ablation study的3种语料：去掉 strcut_code；struct_code 固定替换；struct_code 随机替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "data_path = \"corpus/ds_dict_ori.pkl\"\n",
    "with open(data_path, \"rb\") as f:\n",
    "    ds_dict = pickle.load(f)\n",
    "test_datasets = ds_dict['test']\n",
    "\n",
    "pattern = r'(\\[Structure Token\\] <struct><gstruct_)\\d+(></struct>\\n?)'\n",
    "\n",
    "def replace_with_fixed_number(match):\n",
    "    return f\"{match.group(1)}999{match.group(2)}\"\n",
    "\n",
    "def clean(example):\n",
    "    example['instruction'] = re.sub(pattern, replace_with_fixed_number, example['instruction'])\n",
    "    example['text'] = re.sub(pattern, replace_with_fixed_number, example['text'])\n",
    "    return example\n",
    "\n",
    "for k, td in test_datasets.items():\n",
    "    test_datasets[k] = td.map(clean)\n",
    "for k, td in test_datasets.items():\n",
    "    continue\n",
    "with open(\"./corpus/test_datasets_999.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a698fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/204 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 204/204 [00:00<00:00, 2646.27 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5328.77 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5867.87 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5883.17 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5858.95 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5734.29 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5820.95 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5853.15 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5868.97 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5887.07 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5968.87 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5941.56 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 5951.45 examples/s]\n",
      "Map: 100%|██████████| 148/148 [00:00<00:00, 4881.47 examples/s]\n",
      "Map: 100%|██████████| 148/148 [00:00<00:00, 4873.15 examples/s]\n",
      "Map: 100%|██████████| 4112/4112 [00:00<00:00, 6136.36 examples/s]\n",
      "Map: 100%|██████████| 152/152 [00:00<00:00, 4856.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'instruction': '\\nYou are a chemistry expert. Classify the given molecule into the correct category based on its molecular structure (token) and smiles expression. Each structure token represents a unique graph pattern (e.g., a kind of similar molecular graphs).\\n[Molecule] O1CCC(CC1)CNC(=O)C(Cc1cc2cc(ccc2nc1N)-c1ccccc1C)C\\n[Structure Token] <struct><gstruct_63661></struct>\\n[Task] Is the binding result of the molecular on beta-secretase 1 true or false? Output the complete correct answer from the following two options:\\n1. True\\n2. False\\n[Answer]',\n",
       " 'response': 'True',\n",
       " 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful and reliable assistant.<|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nYou are a chemistry expert. Classify the given molecule into the correct category based on its molecular structure (token) and smiles expression. Each structure token represents a unique graph pattern (e.g., a kind of similar molecular graphs).\\n[Molecule] O1CCC(CC1)CNC(=O)C(Cc1cc2cc(ccc2nc1N)-c1ccccc1C)C\\n[Structure Token] <struct><gstruct_280820></struct>\\n[Task] Is the binding result of the molecular on beta-secretase 1 true or false? Output the complete correct answer from the following two options:\\n1. True\\n2. False\\n[Answer]<|eot_id|><|start_header_id|>LLM Assistant<|end_header_id|>\\n\\nTrue<|eot_id|><|end_of_text|>'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "data_path = \"corpus/ds_dict_ori.pkl\"\n",
    "with open(data_path, \"rb\") as f:\n",
    "    ds_dict = pickle.load(f)\n",
    "test_datasets = ds_dict['test']\n",
    "\n",
    "pattern = r'(\\[Structure Token\\] <struct><gstruct_)\\d+(></struct>\\n?)'\n",
    "\n",
    "def replace_with_random(match):\n",
    "    rand_num = random.randint(1, 999999)\n",
    "    return f\"{match.group(1)}{rand_num}{match.group(2)}\"\n",
    "\n",
    "def clean(example):\n",
    "    example['instruction'] = re.sub(pattern, replace_with_random, example['instruction'])\n",
    "    example['text'] = re.sub(pattern, replace_with_random, example['text'])\n",
    "    return example\n",
    "\n",
    "for k, td in test_datasets.items():\n",
    "    test_datasets[k] = td.map(clean)\n",
    "for k, td in test_datasets.items():\n",
    "    continue\n",
    "with open(\"./corpus/test_datasets_random.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401da74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1631/1631 [00:00<00:00, 6622.64 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6787.17 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6787.66 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6804.58 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6781.66 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6750.49 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6739.13 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6710.72 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6830.97 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6770.06 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6719.14 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6683.74 examples/s]\n",
      "Map: 100%|██████████| 6258/6258 [00:00<00:00, 6770.34 examples/s]\n",
      "Map: 100%|██████████| 1184/1184 [00:00<00:00, 6568.05 examples/s]\n",
      "Map: 100%|██████████| 1184/1184 [00:00<00:00, 6481.98 examples/s]\n",
      "Map: 100%|██████████| 32896/32896 [00:04<00:00, 6584.27 examples/s]\n",
      "Map: 100%|██████████| 1210/1210 [00:00<00:00, 6558.25 examples/s]\n",
      "Map: 100%|██████████| 204/204 [00:00<00:00, 5468.49 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6027.34 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6196.70 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6329.29 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6335.82 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6394.13 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6371.08 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6345.28 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6339.62 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6382.36 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6209.91 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6311.86 examples/s]\n",
      "Map: 100%|██████████| 782/782 [00:00<00:00, 6328.51 examples/s]\n",
      "Map: 100%|██████████| 148/148 [00:00<00:00, 5194.45 examples/s]\n",
      "Map: 100%|██████████| 148/148 [00:00<00:00, 5076.44 examples/s]\n",
      "Map: 100%|██████████| 4112/4112 [00:00<00:00, 6609.68 examples/s]\n",
      "Map: 100%|██████████| 151/151 [00:00<00:00, 5122.99 examples/s]\n",
      "Map: 100%|██████████| 204/204 [00:00<00:00, 5598.48 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6394.76 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6323.44 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6401.45 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6313.18 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6382.80 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6337.65 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6296.75 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6361.86 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6338.70 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6363.19 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6343.16 examples/s]\n",
      "Map: 100%|██████████| 783/783 [00:00<00:00, 6405.23 examples/s]\n",
      "Map: 100%|██████████| 148/148 [00:00<00:00, 5203.20 examples/s]\n",
      "Map: 100%|██████████| 148/148 [00:00<00:00, 5010.23 examples/s]\n",
      "Map: 100%|██████████| 4112/4112 [00:00<00:00, 6684.12 examples/s]\n",
      "Map: 100%|██████████| 152/152 [00:00<00:00, 5158.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "pattern = r'\\[Structure Token\\] <struct><gstruct_\\d+></struct>\\n?'\n",
    "def clean(example):\n",
    "    example['instruction'] = re.sub(pattern, '', example['instruction'])\n",
    "    example['text'] = re.sub(pattern, '', example['text'])\n",
    "    return example\n",
    "\n",
    "data_path = \"corpus/ds_dict_ori.pkl\"\n",
    "with open(data_path, \"rb\") as f:\n",
    "    ds_dict = pickle.load(f)\n",
    "ds_dict_puretext = dict()\n",
    "for split, datasets in ds_dict.items():\n",
    "    for k, td in datasets.items():\n",
    "        datasets[k] = td.map(clean)\n",
    "    ds_dict_puretext[split] = datasets\n",
    "with open(\"./corpus/ds_dict_puretext.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ds_dict_puretext, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
